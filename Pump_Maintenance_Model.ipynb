{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcMSVaa1kWQZWijvtYHSnZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANMOLSHRI8980/Deep-Learning/blob/main/Pump_Maintenance_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMVYQycuuMrt",
        "outputId": "098f78fb-520f-43a2-e07a-0f55dc84d107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data statistics:\n",
            "          flow_rate      pressure          head         power         speed  \\\n",
            "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
            "mean      99.978640     50.067670     29.962612    999.242852   1800.326584   \n",
            "std       10.034624      5.005051      2.974254    100.448707     50.019853   \n",
            "min       60.775997     30.718123     19.034740    553.439614   1585.230451   \n",
            "25%       93.274095     46.689945     27.899544    930.538715   1766.796613   \n",
            "50%       99.974050     50.079234     29.982695    998.961775   1800.478034   \n",
            "75%      106.710809     53.469324     31.991692   1067.903045   1834.191748   \n",
            "max      139.262377     72.395421     41.074874   1372.783334   1976.826583   \n",
            "\n",
            "               npsh  vibration_amplitude  vibration_frequency  \\\n",
            "count  10000.000000         10000.000000         10000.000000   \n",
            "mean      10.001746             0.513806            59.993345   \n",
            "std        1.009735             0.116331             5.034910   \n",
            "min        5.842266             0.127386            37.685157   \n",
            "25%        9.323076             0.436536            56.623617   \n",
            "50%       10.008224             0.508011            59.975822   \n",
            "75%       10.690832             0.579761            63.382978   \n",
            "max       13.745379             1.205324            78.800776   \n",
            "\n",
            "       motor_temperature  bearing_temperature  ...       voltage  \\\n",
            "count       10000.000000         10000.000000  ...  10000.000000   \n",
            "mean           70.025774            60.578162  ...    220.017909   \n",
            "std             5.007393             5.668183  ...      9.959764   \n",
            "min            52.865085            41.474250  ...    182.053626   \n",
            "25%            66.721515            56.834115  ...    213.186554   \n",
            "50%            69.962495            60.277698  ...    220.043904   \n",
            "75%            73.326355            63.958175  ...    226.827268   \n",
            "max            89.148911            91.753633  ...    265.621147   \n",
            "\n",
            "             torque  runtime_hours  ambient_temperature      humidity  \\\n",
            "count  10000.000000   10000.000000         10000.000000  10000.000000   \n",
            "mean      99.980784   59505.261772            25.009590     50.149142   \n",
            "std        9.873132   34377.884443             2.993150     11.580911   \n",
            "min       63.775290       8.831496            14.720921     30.000092   \n",
            "25%       93.250845   29733.459815            23.007118     40.075436   \n",
            "50%       99.910799   59581.821275            24.974569     50.107058   \n",
            "75%      106.596754   89295.063509            27.010976     60.051266   \n",
            "max      139.768682  119323.179822            35.878399     69.997191   \n",
            "\n",
            "        noise_level  bearing_frequency  bearing_amplitude  start_stop_cycles  \\\n",
            "count  10000.000000       10000.000000       10000.000000       10000.000000   \n",
            "mean      71.040466         101.906731           0.105038        2521.817600   \n",
            "std        6.867351          13.466352           0.030533        1456.583657   \n",
            "min       52.791332          61.304309           0.023164           0.000000   \n",
            "25%       66.831256          93.437734           0.087507        1267.000000   \n",
            "50%       70.359772         100.610845           0.101610        2521.000000   \n",
            "75%       74.015485         107.965126           0.116114        3781.250000   \n",
            "max      112.434467         175.538978           0.338335        5057.000000   \n",
            "\n",
            "            failure  \n",
            "count  10000.000000  \n",
            "mean       0.050500  \n",
            "std        0.218985  \n",
            "min        0.000000  \n",
            "25%        0.000000  \n",
            "50%        0.000000  \n",
            "75%        0.000000  \n",
            "max        1.000000  \n",
            "\n",
            "[8 rows x 24 columns]\n",
            "\n",
            "Failure rate:\n",
            "0.0505\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def generate_dummy_data(n_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    data = {\n",
        "        'flow_rate': np.random.normal(100, 10, n_samples),  # m³/h (cubic meters per hour)\n",
        "        'pressure': np.random.normal(50, 5, n_samples),  # bar\n",
        "        'head': np.random.normal(30, 3, n_samples),  # m (meters)\n",
        "        'power': np.random.normal(1000, 100, n_samples),  # kW (kilowatts)\n",
        "        'speed': np.random.normal(1800, 50, n_samples),  # rpm (revolutions per minute)\n",
        "        'npsh': np.random.normal(10, 1, n_samples),  # m (meters)\n",
        "        'vibration_amplitude': np.random.normal(0.5, 0.1, n_samples),  # mm/s (millimeters per second)\n",
        "        'vibration_frequency': np.random.normal(60, 5, n_samples),  # Hz (Hertz)\n",
        "        'motor_temperature': np.random.normal(70, 5, n_samples),  # °C (degrees Celsius)\n",
        "        'bearing_temperature': np.random.normal(60, 5, n_samples),  # °C (degrees Celsius)\n",
        "        'inlet_pressure': np.random.normal(30, 3, n_samples),  # bar\n",
        "        'outlet_pressure': np.random.normal(80, 5, n_samples),  # bar\n",
        "        'water_velocity': np.random.normal(5, 0.5, n_samples),  # m/s (meters per second)\n",
        "        'current_draw': np.random.normal(50, 5, n_samples),  # A (Amperes)\n",
        "        'voltage': np.random.normal(220, 10, n_samples),  # V (Volts)\n",
        "        'torque': np.random.normal(100, 10, n_samples),  # Nm (Newton meters)\n",
        "        'runtime_hours': np.cumsum(np.random.uniform(0, 24, n_samples)),  # hours\n",
        "        'ambient_temperature': np.random.normal(25, 3, n_samples),  # °C (degrees Celsius)\n",
        "        'humidity': np.random.uniform(30, 70, n_samples),  # % (percentage)\n",
        "        'noise_level': np.random.normal(70, 5, n_samples),  # dB (decibels)\n",
        "        'bearing_frequency': np.random.normal(100, 10, n_samples),  # Hz (Hertz)\n",
        "        'bearing_amplitude': np.random.normal(0.1, 0.02, n_samples),  # g (acceleration due to gravity)\n",
        "        'start_stop_cycles': np.cumsum(np.random.randint(0, 2, n_samples))  # count (unitless)\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # failure events\n",
        "    df['failure'] = 0\n",
        "    failure_probability = 0.05\n",
        "    df.loc[np.random.random(n_samples) < failure_probability, 'failure'] = 1\n",
        "\n",
        "    # correlations between features and failures\n",
        "    df.loc[df['failure'] == 1, 'vibration_amplitude'] *= 1.5\n",
        "    df.loc[df['failure'] == 1, 'bearing_temperature'] *= 1.2\n",
        "    df.loc[df['failure'] == 1, 'noise_level'] *= 1.3\n",
        "    df.loc[df['failure'] == 1, 'bearing_frequency'] *= 1.4\n",
        "    df.loc[df['failure'] == 1, 'bearing_amplitude'] *= 2.0\n",
        "\n",
        "    return df\n",
        "\n",
        "# Generating dummy data\n",
        "data = generate_dummy_data(10000)\n",
        "\n",
        "data.to_excel(\"enhanced_pump_maintenance_data_with_units.xlsx\", index=False)\n",
        "\n",
        "print(\"\\nData statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "print(\"\\nFailure rate:\")\n",
        "print(data['failure'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.impute import SimpleImputer\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "from sklearn.manifold import TSNE\n",
        "import os\n",
        "\n",
        "class EnhancedAdvancedHybridPumpMaintenanceModel:\n",
        "    def __init__(self, sequence_length=50):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.scaler = StandardScaler()\n",
        "        self.imputer = SimpleImputer(strategy='mean')\n",
        "        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "        self.svm_model = SVC(probability=True, random_state=42, class_weight='balanced')\n",
        "        self.xgb_model = XGBClassifier(random_state=42, scale_pos_weight=19)\n",
        "        self.lstm_model = None\n",
        "        self.autoencoder = None\n",
        "        self.arima_models = {}\n",
        "        self.stacking_model = None\n",
        "        self.feature_selector = None\n",
        "\n",
        "    def preprocess_data(self, X, y=None, is_training=True):\n",
        "        X = self.imputer.fit_transform(X) if is_training else self.imputer.transform(X)\n",
        "        X = self.scaler.fit_transform(X) if is_training else self.scaler.transform(X)\n",
        "        if y is not None:\n",
        "            return X, y\n",
        "        return X\n",
        "\n",
        "    def create_sequences(self, X, y=None):\n",
        "        X_seq = []\n",
        "        y_seq = []\n",
        "        for i in range(len(X) - self.sequence_length + 1):\n",
        "            X_seq.append(X[i:i+self.sequence_length])\n",
        "            if y is not None:\n",
        "                y_seq.append(y[i+self.sequence_length-1])\n",
        "        return np.array(X_seq), np.array(y_seq) if y is not None else None\n",
        "\n",
        "    def build_lstm_model(self, input_shape):\n",
        "        model = Sequential([\n",
        "            Bidirectional(LSTM(64, return_sequences=True, input_shape=input_shape)),\n",
        "            Dropout(0.2),\n",
        "            Bidirectional(LSTM(32, return_sequences=True)),\n",
        "            Dropout(0.2),\n",
        "            TimeDistributed(Dense(16, activation='relu')),\n",
        "            LSTM(16),\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def build_autoencoder(self, input_shape):\n",
        "        model = Sequential([\n",
        "            Dense(32, activation=\"relu\", input_shape=input_shape),\n",
        "            Dense(16, activation=\"relu\"),\n",
        "            Dense(8, activation=\"relu\"),\n",
        "            Dense(16, activation=\"relu\"),\n",
        "            Dense(32, activation=\"relu\"),\n",
        "            Dense(input_shape[0], activation=\"linear\")\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_processed, y = self.preprocess_data(X, y)\n",
        "\n",
        "        X_resampled, y_resampled = self._resample(X_processed, y)\n",
        "\n",
        "        # Feature selection\n",
        "        self.feature_selector = SelectFromModel(XGBClassifier(random_state=42))\n",
        "        X_selected = self.feature_selector.fit_transform(X_resampled, y_resampled)\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_selected, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train traditional ML models\n",
        "        self.rf_model.fit(X_train, y_train)\n",
        "        self.svm_model.fit(X_train, y_train)\n",
        "        self.xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Prepare sequences for LSTM\n",
        "        X_seq, y_seq = self.create_sequences(X_selected, y_resampled)\n",
        "        X_seq_train, X_seq_val, y_seq_train, y_seq_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train LSTM model\n",
        "        self.lstm_model = self.build_lstm_model((X_seq.shape[1], X_seq.shape[2]))\n",
        "        self.lstm_model.fit(X_seq_train, y_seq_train, validation_data=(X_seq_val, y_seq_val), epochs=5, batch_size=32, verbose=1)\n",
        "\n",
        "        # Train autoencoder\n",
        "        self.autoencoder = self.build_autoencoder((X_selected.shape[1],))\n",
        "        self.autoencoder.fit(X_selected, X_selected, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "        # Train ARIMA models for each feature\n",
        "        for i in range(X_selected.shape[1]):\n",
        "            try:\n",
        "                model = ARIMA(X_selected[:, i], order=(1,1,1))\n",
        "                self.arima_models[i] = model.fit()\n",
        "            except:\n",
        "                print(f\"Unable to fit ARIMA model for feature {i}\")\n",
        "\n",
        "        # Train stacking ensemble\n",
        "        base_models = [\n",
        "            ('rf', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')),\n",
        "            ('svm', SVC(probability=True, random_state=42, class_weight='balanced')),\n",
        "            ('xgb', XGBClassifier(random_state=42, scale_pos_weight=19))\n",
        "        ]\n",
        "        self.stacking_model = StackingClassifier(estimators=base_models, final_estimator=RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))\n",
        "        self.stacking_model.fit(X_train, y_train)\n",
        "\n",
        "    def visualize_results(self, X, y, predictions_1, predictions_2, predictions_3, anomaly_scores, arima_forecasts):\n",
        "        plt.figure(figsize=(20, 30))\n",
        "\n",
        "        # 1. Failure Probability (Different Approaches)\n",
        "        plt.subplot(5, 2, 1)\n",
        "        plt.plot(predictions_1, label='Approach 1')\n",
        "        plt.plot(predictions_2, label='Approach 2')\n",
        "        plt.plot(predictions_3, label='Approach 3')\n",
        "        plt.title('Failure Probability (Different Approaches)')\n",
        "        plt.legend()\n",
        "\n",
        "        # 2. Anomaly Scores\n",
        "        plt.subplot(5, 2, 2)\n",
        "        plt.plot(anomaly_scores)\n",
        "        plt.title('Anomaly Scores')\n",
        "\n",
        "        # 3. ARIMA Forecast (First Feature)\n",
        "        plt.subplot(5, 2, 3)\n",
        "        plt.plot(arima_forecasts[:, 0])\n",
        "        plt.title('ARIMA Forecast (First Feature)')\n",
        "\n",
        "        # 4. Actual vs Predicted Failures\n",
        "        plt.subplot(5, 2, 4)\n",
        "        plt.plot(y, label='Actual')\n",
        "        plt.plot((predictions_3 > 0.5).astype(int), label='Predicted (Approach 3)')\n",
        "        plt.title('Actual vs Predicted Failures')\n",
        "        plt.legend()\n",
        "\n",
        "        # 5. Feature Importance\n",
        "        feature_importance = self.rf_model.feature_importances_\n",
        "        feature_names = X.columns[self.feature_selector.get_support()]\n",
        "        importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
        "        importance_df = importance_df.sort_values('importance', ascending=False)\n",
        "\n",
        "        plt.subplot(5, 2, 5)\n",
        "        sns.barplot(x='importance', y='feature', data=importance_df.head(10))\n",
        "        plt.title('Top 10 Feature Importance')\n",
        "\n",
        "        # 6. Confusion Matrix\n",
        "        plt.subplot(5, 2, 6)\n",
        "        cm = confusion_matrix(y[self.sequence_length-1:], (predictions_3[self.sequence_length-1:] > 0.5).astype(int))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "\n",
        "        # 7. ROC Curve\n",
        "        plt.subplot(5, 2, 7)\n",
        "        fpr, tpr, _ = roc_curve(y[self.sequence_length-1:], predictions_3[self.sequence_length-1:])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "\n",
        "        # 8. Anomaly Score Distribution\n",
        "        plt.subplot(5, 2, 8)\n",
        "        sns.histplot(anomaly_scores, kde=True)\n",
        "        plt.title('Anomaly Score Distribution')\n",
        "\n",
        "        # 9. Time Series of Key Features\n",
        "        plt.subplot(5, 2, 9)\n",
        "        for feature in importance_df['feature'].head(3):  # Plot top 3 important features\n",
        "            plt.plot(X[feature], label=feature)\n",
        "        plt.title('Time Series of Top 3 Important Features')\n",
        "        plt.legend()\n",
        "\n",
        "        # 10. t-SNE Visualization\n",
        "        plt.subplot(5, 2, 10)\n",
        "        tsne = TSNE(n_components=2, random_state=42)\n",
        "        X_processed = self.preprocess_data(X, is_training=False)\n",
        "        X_selected = self.feature_selector.transform(X_processed)\n",
        "        X_tsne = tsne.fit_transform(X_selected)\n",
        "        plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis')\n",
        "        plt.title('t-SNE Visualization of Features')\n",
        "        plt.colorbar(label='Failure')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def _resample(self, X, y):\n",
        "        X_majority = X[y == 0]\n",
        "        X_minority = X[y == 1]\n",
        "        y_majority = y[y == 0]\n",
        "        y_minority = y[y == 1]\n",
        "\n",
        "        X_minority_upsampled, y_minority_upsampled = resample(\n",
        "            X_minority, y_minority, replace=True, n_samples=len(X_majority), random_state=42\n",
        "        )\n",
        "\n",
        "        X_resampled = np.vstack((X_majority, X_minority_upsampled))\n",
        "        y_resampled = np.hstack((y_majority, y_minority_upsampled))\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_processed = self.preprocess_data(X, is_training=False)\n",
        "        X_selected = self.feature_selector.transform(X_processed)\n",
        "\n",
        "        rf_pred = self.rf_model.predict_proba(X_selected)[:, 1]\n",
        "        svm_pred = self.svm_model.predict_proba(X_selected)[:, 1]\n",
        "        xgb_pred = self.xgb_model.predict_proba(X_selected)[:, 1]\n",
        "\n",
        "        X_seq, _ = self.create_sequences(X_selected)\n",
        "        lstm_pred = self.lstm_model.predict(X_seq).flatten()\n",
        "\n",
        "        stacking_pred = self.stacking_model.predict_proba(X_selected)[:, 1]\n",
        "\n",
        "        reconstructed = self.autoencoder.predict(X_selected)\n",
        "        mse = np.mean(np.power(X_selected - reconstructed, 2), axis=1)\n",
        "        anomaly_scores = (mse - np.min(mse)) / (np.max(mse) - np.min(mse))\n",
        "\n",
        "        arima_forecasts = np.zeros_like(X_selected)\n",
        "        for i in range(X_selected.shape[1]):\n",
        "            if i in self.arima_models:\n",
        "                forecast = self.arima_models[i].forecast(steps=1)\n",
        "                arima_forecasts[:, i] = forecast\n",
        "\n",
        "        combined_pred_1 = self._combine_predictions_approach_1(rf_pred, svm_pred, xgb_pred, lstm_pred, stacking_pred, anomaly_scores)\n",
        "        combined_pred_2 = self._combine_predictions_approach_2(rf_pred, svm_pred, xgb_pred, lstm_pred, stacking_pred, anomaly_scores)\n",
        "        combined_pred_3 = self._combine_predictions_approach_3(rf_pred, svm_pred, xgb_pred, lstm_pred, stacking_pred, anomaly_scores)\n",
        "\n",
        "        return combined_pred_1, combined_pred_2, combined_pred_3, anomaly_scores, arima_forecasts\n",
        "\n",
        "    def _combine_predictions_approach_1(self, rf_pred, svm_pred, xgb_pred, lstm_pred, stacking_pred, anomaly_scores):\n",
        "        n = len(rf_pred)\n",
        "        m = len(lstm_pred)\n",
        "        pad_length = n - m\n",
        "        lstm_pred_padded = np.pad(lstm_pred, (0, pad_length), mode='edge')\n",
        "        return (rf_pred + svm_pred + xgb_pred + lstm_pred_padded + stacking_pred + anomaly_scores) / 6\n",
        "\n",
        "    def _combine_predictions_approach_2(self, rf_pred, svm_pred, xgb_pred, lstm_pred, stacking_pred, anomaly_scores):\n",
        "        n = len(rf_pred)\n",
        "        m = len(lstm_pred)\n",
        "        combined_pred = np.zeros(n)\n",
        "        combined_pred[:m] = (rf_pred[:m] + svm_pred[:m] + xgb_pred[:m] + lstm_pred + stacking_pred[:m] + anomaly_scores[:m]) / 6\n",
        "        combined_pred[m:] = (rf_pred[m:] + svm_pred[m:] + xgb_pred[m:] + stacking_pred[m:] + anomaly_scores[m:]) / 5\n",
        "        return combined_pred\n",
        "\n",
        "    def _combine_predictions_approach_3(self, rf_pred, svm_pred, xgb_pred, lstm_pred, stacking_pred, anomaly_scores):\n",
        "        n = len(rf_pred)\n",
        "        m = len(lstm_pred)\n",
        "        pad_length = n - m\n",
        "        lstm_pred_padded = np.pad(lstm_pred, (0, pad_length), mode='edge')\n",
        "        weights = np.array([0.2, 0.15, 0.2, 0.25, 0.15, 0.05])\n",
        "        return np.average(np.vstack((rf_pred, svm_pred, xgb_pred, lstm_pred_padded, stacking_pred, anomaly_scores)), axis=0, weights=weights)\n",
        "\n",
        "def generate_dummy_data(n_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    vibration = np.random.normal(0, 1, n_samples)\n",
        "    temperature = np.random.normal(60, 10, n_samples)\n",
        "    pressure = np.random.normal(100, 15,n_samples)"
      ],
      "metadata": {
        "id": "koMgroSJsPCu"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}